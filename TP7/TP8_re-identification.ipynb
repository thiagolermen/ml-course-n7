{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSgiKnAs1BbN"
   },
   "source": [
    "**Practical session nÂ°8** : Re-identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1waEt7NJgSx"
   },
   "source": [
    "The first part of the practical work demonstrated how it is possible to sort in ascending order a set of inputs based on pairs of ordered images. The method involved training Siamese CNNs with a single terminal neuron, penalizing incorrectly ordered pairs of outputs.\n",
    "\n",
    "In this section, we address a problem of a somewhat similar nature: we have access to a set of input pairs containing the same object presented in different ways. The goal is to train the network in such a way that two inputs corresponding to the same object are \"close\" in the output space.\n",
    "\n",
    "This could, for example, involve people photographed [from different angles](http://vis-www.cs.umass.edu/lfw/). In this case, a common motivation is to [re-identify](https://arxiv.org/pdf/2001.04193.pdf) a person in surveillance video images. \\\n",
    "The task then resembles a classification. The nuance is that the classes are not predefined. The task also resembles clustering. The difference lies in the availability of images from the same class (supervised vs. unsupervised).\n",
    "\n",
    "In this practical work, we present the basics of two now-classic approaches, the second of which can be seen as an improvement on the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qtq1hUDdoSDC"
   },
   "source": [
    "**Exercise #1**\n",
    "\n",
    "We will use MNIST to illustrate a first method. In MNIST, the number of classes is limited to ten. Therefore, we will not attempt to showcase a model's ability to re-identify new symbols. \\\n",
    "The goal is simply to demonstrate that by using pairs of images containing the same object (the same digit) and pairs of images containing two different objects, it is possible to train a network to separate the images in the output space, which we again refer to as the **latent space**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN5yHq5CZgIq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "\n",
    "ls = lambda rep: sorted(os.listdir(rep))\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Dmuz3xRETgm",
    "outputId": "994225fd-d1d2-4b6a-da58-dc39394a7065"
   },
   "outputs": [],
   "source": [
    "# Getting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OGKlP_aGy2y"
   },
   "source": [
    "**Q1** Run the following cells (loading MNIST and defining the dataset). What are the three tensors generated by the DigitPairsDataset ? What is the specificity of the test loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yL4auBL00xyc"
   },
   "outputs": [],
   "source": [
    "# Reorganization of the dataset (zeros first, then ones, then twos, etc.)\n",
    "# Load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True)#, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True)#, transform=transforms.ToTensor())\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.9 * len(mnist_train))\n",
    "val_size = int(0.1 * len(mnist_train))\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    mnist_train, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "def create_dict(dataset):\n",
    "    # Organize data into a dictionary\n",
    "    dict_ = {i: [] for i in range(10)}  # Create an empty list for each digit (0 to 9)\n",
    "\n",
    "    for image, label in dataset:\n",
    "        dict_[label].append(np.array(image))\n",
    "    for k in dict_.keys():\n",
    "        dict_[k] = np.array(dict_[k])\n",
    "    return dict_\n",
    "\n",
    "train_dict = create_dict(train_dataset)\n",
    "val_dict = create_dict(val_dataset)\n",
    "test_dict = create_dict(test_dataset)\n",
    "\n",
    "data = {'train':train_dict, 'val':val_dict, 'test':test_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2oZAkRQ0aCp",
    "outputId": "8715d4d3-33bb-4528-a6cd-99e06f4f078e"
   },
   "outputs": [],
   "source": [
    "# Display the number of images for each digit\n",
    "for digit, images in train_dict.items():\n",
    "    print(f\"Digit {digit}: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKRyNx0jsf6-"
   },
   "outputs": [],
   "source": [
    "# For generating pairs\n",
    "class DigitPairsDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.class_sizes = {}\n",
    "        for i in range(10):\n",
    "            self.class_sizes[i] = data_dict[i].shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        # Randomly choose if the pair is from the same digit (y=0) or different digits (y=1)\n",
    "        y = torch.randint(0, 2, (1,)).item()\n",
    "\n",
    "        # Randomly select two different digits\n",
    "        two_digits = torch.multinomial(torch.ones(10), 2)\n",
    "        digit = two_digits[0].item()\n",
    "\n",
    "        # Randomly select images from the chosen digit\n",
    "        idx_0 = np.random.randint(0, self.class_sizes[digit] - 1)\n",
    "        image0 = self.data_dict[digit][idx_0]\n",
    "\n",
    "        if y==1:\n",
    "            # If different digits, select a different digit\n",
    "            other_digit = two_digits[1].item()\n",
    "        else:\n",
    "            other_digit = digit\n",
    "        idx_1 = np.random.randint(0, self.class_sizes[other_digit] - 1)\n",
    "        image1 = self.data_dict[other_digit][idx_1]\n",
    "\n",
    "        if self.transform:\n",
    "            image0 = self.transform(image0)\n",
    "            image1 = self.transform(image1)\n",
    "\n",
    "        return image0, image1, y\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for i in range(10):\n",
    "            length += self.class_sizes[i]\n",
    "        return  length\n",
    "\n",
    "# For iterating over test data\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.class_sizes = {}\n",
    "        for i in range(10):\n",
    "            self.class_sizes[i] = data_dict[i].shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "\n",
    "        digit = torch.randint(0, 10, (1,)).item()\n",
    "        idx = np.random.randint(0, self.class_sizes[digit] - 1)\n",
    "        image = self.data_dict[digit][idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, digit\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for i in range(10):\n",
    "            length += self.class_sizes[i]\n",
    "        return  length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQ43f1wMImMH"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "                    [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.RandomAffine(degrees=10, translate=(0.1,0.1), scale=(0.9, 1.1)),\n",
    "                    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                    ])\n",
    "transforms_dict = {'train': train_transform, 'val':transforms.ToTensor(), 'test':transforms.ToTensor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzHjgZfmKup2"
   },
   "outputs": [],
   "source": [
    "datasets_dict = {phase : DigitPairsDataset(data[phase], transforms_dict[phase]) \\\n",
    "              for phase in ['train','val']}\n",
    "datasets_dict['test'] = TestDataset(data['test'], transforms_dict['test'])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Data loaders\n",
    "dataloaders_dict = {phase : DataLoader(datasets_dict[phase], shuffle = True, batch_size=batch_size, num_workers=2)\\\n",
    "              for phase in ['train', 'val']}\n",
    "\n",
    "dataloaders_dict['test'] = DataLoader(datasets_dict['test'], shuffle = False, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "id": "_KSs3ihqKSg-",
    "outputId": "16c7f9ae-7628-4436-9e3c-2d0dde92ab77"
   },
   "outputs": [],
   "source": [
    "# Get a batch from the 'train' dataloader\n",
    "image0, image1, y = next(iter(dataloaders_dict['train']))\n",
    "\n",
    "# y values\n",
    "print('y:', y[0:4])\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    # Plot the first image\n",
    "    axes[0, i].imshow(image0[i, 0, ...], cmap='gray')\n",
    "    axes[0, i].set_title((\"Image 0 |\" if i == 0 else \"\") + (\" Differents\" if y[i] else \" Same\"))\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    # Plot the second image\n",
    "    axes[1, i].imshow(image1[i, 0, ...], cmap='gray')\n",
    "    axes[1, i].set_title(\"Image 1\" if i == 0 else \"\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuJS9-bxTNrg"
   },
   "source": [
    "**Q2** To separate the small images in the latent space, we will penalize discrepancies when the digit is the same and penalize proximity when the digit is different.\n",
    "The notion of proximity needs clarification. [Historically](https://proceedings.neurips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf), cosine similarity was first used.\n",
    "How is this similarity defined?\n",
    "\n",
    "Complete the following cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgPPGekea31M"
   },
   "outputs": [],
   "source": [
    "class ContrastiveCos(nn.Module):\n",
    "    def __init__(self, margin=0.):\n",
    "        super(ContrastiveCos, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "\n",
    "    def forward(self, output0, output1, y):\n",
    "        # Calculate cosine similarity\n",
    "        cos_similarity = self.cos(output0, output1)\n",
    "\n",
    "        # Contrastive loss calculation\n",
    "        # case (y=1), images from different classes (minimize similarity)\n",
    "        positive_loss = y * torch.relu(cos_similarity - self.margin)\n",
    "        # case (y=0), images from the same class (maximize similarity)\n",
    "        negative_loss = (1 - y) * torch.relu(1 - cos_similarity)\n",
    "        losses = positive_loss + negative_loss\n",
    "\n",
    "        # Calculate the mean of the losses\n",
    "        return losses.mean()\n",
    "\n",
    "loss_fn = ContrastiveCos(margin=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMBQoe9OU7l1"
   },
   "source": [
    "**Q3** Define a small CNN and train it with this loss function for ten epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "qm5U7h-LX7xN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcef2034cfb46fe69e39e9b53698a85d",
     "grade": false,
     "grade_id": "cell-8135af9abae9443b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 490\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(N, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x\n",
    "\n",
    "# Move the model to the current device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "AQv39vS896qQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36616cbf10a5322289507b641b122087",
     "grade": false,
     "grade_id": "cell-52c2b70ca77ea161",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "de40e216-6f17-4fa3-a752-a375b1cf2311",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, notebook\n",
    "\n",
    "num_epochs = 10\n",
    "losses = {'train':[], 'val':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "        running_loss = 0.\n",
    "\n",
    "        # Use tqdm for progress tracking\n",
    "        data_loader = notebook.tqdm(dataloaders_dict[phase], desc=f'{phase.capitalize()} Epoch {epoch}', leave=phase=='train')\n",
    "\n",
    "        for x0, x1, y in data_loader:\n",
    "            x0, x1, y = x0.to(device), x1.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # YOUR CODE HERE\n",
    "                raise NotImplementedError()\n",
    "                if phase == 'train':\n",
    "                    # Compute gradient and update model's parameters\n",
    "                    # YOUR CODE HERE\n",
    "                    raise NotImplementedError()\n",
    "                running_loss += loss.item() * x0.shape[0]\n",
    "\n",
    "            data_loader.set_postfix(loss=f'{loss.item():.4f}', refresh=False)\n",
    "\n",
    "        epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "        losses[phase].append(epoch_loss)\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVbyCTSeVLMs"
   },
   "source": [
    "**Q4** Visualize results and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "deletable": false,
    "id": "aylUtLFnoyC6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cf7117a05a155269b3afd8b1471a137",
     "grade": false,
     "grade_id": "cell-90854ad8108fcf30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "049890b6-aa41-45b2-ba5d-f4ebf0ecd049",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for image, label in dataloaders_dict['test']:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        output = F.normalize(output, p=2.0, dim=1, eps=1e-12)\n",
    "        outputs.append(output)\n",
    "        labels.append(label)\n",
    "\n",
    "labels = torch.cat(labels)\n",
    "outputs = torch.cat(outputs)\n",
    "# Sort outputs according to true labels\n",
    "sorted_indices = np.argsort(labels)\n",
    "labels = labels[sorted_indices]\n",
    "# Reorganize the outputs based on labels\n",
    "outputs = outputs[sorted_indices]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "scatter = ax.scatter(outputs.numpy()[:, 0], outputs.numpy()[:, 2], c=labels.numpy(), cmap='tab10', alpha=0.8)\n",
    "fig.colorbar(scatter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zyTkBMzWy-E"
   },
   "source": [
    "**Q5** Using the *sim_matrix* function, visualize the distance matrix between test outputs. What accuracy can be achieved at best on a classification task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDk2eYoPAjoI"
   },
   "outputs": [],
   "source": [
    "def sim_matrix(a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the similarity matrix between two matrices.\n",
    "\n",
    "    Args:\n",
    "        a (torch.Tensor): First input matrix.\n",
    "        b (torch.Tensor): Second input matrix.\n",
    "        eps (float): Small value for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Similarity matrix.\n",
    "    \"\"\"\n",
    "    # 1) Normalize\n",
    "    a_norm, b_norm = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_normalized = a / torch.max(a_norm, eps * torch.ones_like(a_norm))\n",
    "    b_normalized = b / torch.max(b_norm, eps * torch.ones_like(b_norm))\n",
    "\n",
    "    # 2) Compute the product X * tX\n",
    "    sim_matrix = torch.matmul(a_normalized, b_normalized.transpose(0, 1))\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "QLg9XXFmACkQ",
    "outputId": "45a1ddc5-90d8-4d9f-aaef-aa8588803be3"
   },
   "outputs": [],
   "source": [
    "# Calculate the distance matrix\n",
    "distances = 1 - sim_matrix(outputs, outputs)\n",
    "\n",
    "# Plot the distance matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "threshold = 0.5  # Set the threshold for visualization\n",
    "binary_distances = 1*(distances > threshold)\n",
    "\n",
    "plt.imshow(distances, vmin=0., vmax=1.,cmap='hot', aspect='auto')  # 'aspect' ensures proper aspect ratio\n",
    "#plt.imshow(binary_distances, vmin=0., vmax=1.,cmap='hot', aspect='auto')  # 'aspect' ensures proper aspect ratio\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distance Matrix')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Sample Index')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YV4hh7U8EZK_",
    "outputId": "891149f7-b52a-46d8-cc16-fbd449da3616"
   },
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "threshold = 0.1\n",
    "binary_distances = distances < threshold\n",
    "for label in range(10):\n",
    "    # submatrix indices\n",
    "    sub_ind = labels==label\n",
    "    correct_predictions += binary_distances[sub_ind,:][:,sub_ind].sum().item()**0.5\n",
    "accuracy = correct_predictions / len(labels)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAlhzhJkGuqo",
    "outputId": "43e4a279-07ec-4489-bdd3-747446337088"
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.1,0.5,10)\n",
    "for threshold in thresholds:\n",
    "    binary_distances = distances < threshold\n",
    "    correct_predictions = 0\n",
    "    for label in range(10):\n",
    "        # submatrix indices\n",
    "        sub_ind = labels==label\n",
    "        correct_predictions += binary_distances[sub_ind,:][:,sub_ind].sum().item()**0.5\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    print('Threshold :  {:.4f}'.format(threshold))\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCwhN0pqoXhb"
   },
   "source": [
    "**Exercise #2**\n",
    "\n",
    "On datasets more complex than MNIST, a simple idea has significantly enhanced separation in the \"latent space.\" The concept involves not sampling pairs of images but rather [triplets](https://arxiv.org/pdf/1503.03832.pdf). In these triplets, we ensure that two images feature the same object (the \"anchor\" image and the \"positive\" image), while the third one contains a different object (the \"negative\" image). In the simplest form, the contrastive loss is applied simultaneously to the pairs (anchor, positive) and (anchor, negative).\n",
    "\n",
    "The illustrated version here corresponds to this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5LMOwNfxFcs"
   },
   "source": [
    "**Q1** Complete the DigitTripletDataset class to be able to generate a triplet (anchor, positive, negative). Visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "oMtIbGJqO3wh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d750f692b63ae4d5d4f7bda226ed5bed",
     "grade": false,
     "grade_id": "cell-49e363bd522c184f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For generating pairs\n",
    "class DigitTripletDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.class_sizes = {}\n",
    "        for i in range(10):\n",
    "            self.class_sizes[i] = data_dict[i].shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        # Randomly choose if the pair is from the same digit (y=0) or different digits (y=1)\n",
    "        y = torch.randint(0, 2, (1,)).item()\n",
    "\n",
    "        # Randomly select two different digits\n",
    "        two_digits = torch.multinomial(torch.ones(10), 2)\n",
    "        digit = two_digits[0].item()\n",
    "        different_digit = two_digits[1].item()\n",
    "\n",
    "        # Randomly select images from the chosen digit\n",
    "        idx_0 = np.random.randint(0, self.class_sizes[digit] - 1)\n",
    "        anchor_image = self.data_dict[digit][idx_0]\n",
    "        # Select positive and negative images\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        if self.transform:\n",
    "            anchor_image = self.transform(anchor_image)\n",
    "            positive_image = self.transform(positive_image)\n",
    "            negative_image = self.transform(negative_image)\n",
    "\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for i in range(10):\n",
    "            length += self.class_sizes[i]\n",
    "        return  length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbXXmN64QhFY"
   },
   "outputs": [],
   "source": [
    "# Update the dataloaders\n",
    "batch_size = 64\n",
    "for phase in ['train','val']:\n",
    "    datasets_dict[phase] = DigitTripletDataset(data[phase], transforms_dict[phase])\n",
    "    dataloaders_dict[phase] = DataLoader(datasets_dict[phase], shuffle = True, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "id": "5vqwM5n6SHMj",
    "outputId": "e97df6bf-3143-4ce4-c81f-3a39c6de9694"
   },
   "outputs": [],
   "source": [
    "# Get a batch from the 'train' dataloader\n",
    "anchor, positive, negative = next(iter(dataloaders_dict['train']))\n",
    "\n",
    "# y values\n",
    "print('y:', y[0:4])\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "for i in range(4):\n",
    "    # Plot the anchor image\n",
    "    axes[0, i].imshow(anchor[i, 0, ...], cmap='gray')\n",
    "    axes[0, i].set_title(\"Anchor image\")\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    # Plot the positive image\n",
    "    axes[1, i].imshow(positive[i, 0, ...], cmap='gray')\n",
    "    axes[1, i].set_title(\"Positive image\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "    # Plot the negative image\n",
    "    axes[2, i].imshow(negative[i, 0, ...], cmap='gray')\n",
    "    axes[2, i].set_title(\"Negative image\")\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-ZdBo9uU63e"
   },
   "source": [
    "**Q2** Complete the definition of the triplet loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccnJixPs1GfA"
   },
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        cosap = self.cos(anchor, positive)\n",
    "        cosan = self.cos(anchor, negative)\n",
    "        losses = torch.relu((1 - cosap) - (1 - cosan) + self.margin)\n",
    "\n",
    "        return losses.mean()\n",
    "\n",
    "loss_fn = TripletLoss(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsYFGO23xH_D"
   },
   "source": [
    "**Q3** EntraÃ®ner le mÃªme modÃ¨le que dans l'exercice nÂ°2 et comparer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdinYhS82sMq"
   },
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "haubGFqVWPQP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "765500fcb0c7442f9765a0f8e2bdc64f",
     "grade": false,
     "grade_id": "cell-1ae39e1c8259eb15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "8b72d43f-b578-405e-e24f-88b98f22b2b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "losses = {'train':[], 'val':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "        running_loss = 0.\n",
    "\n",
    "        # Use tqdm for progress tracking\n",
    "        data_loader = notebook.tqdm(dataloaders_dict[phase], desc=f'{phase.capitalize()} Epoch {epoch}', leave=phase=='train')\n",
    "\n",
    "        for anchor, positive, negative in data_loader:\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # YOUR CODE HERE\n",
    "                raise NotImplementedError()\n",
    "                running_loss += loss.item() * x0.shape[0]\n",
    "\n",
    "            data_loader.set_postfix(loss=f'{loss.item():.4f}', refresh=False)\n",
    "\n",
    "        epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "        losses[phase].append(epoch_loss)\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "deletable": false,
    "id": "WgkeqdioY8Iq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b75ed04714d30c57a989b7cbff06f85b",
     "grade": false,
     "grade_id": "cell-d696d89ab941c7fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "4ffeec64-c34e-4e44-f7ac-5aa1f80cc722",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "    for image, label in dataloaders_dict['test']:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        output = F.normalize(output, p=2.0, dim=1, eps=1e-12)\n",
    "        outputs.append(output)\n",
    "        labels.append(label)\n",
    "\n",
    "labels = torch.cat(labels)\n",
    "outputs = torch.cat(outputs)\n",
    "# Sort outputs according to true labels\n",
    "sorted_indices = np.argsort(labels)\n",
    "labels = labels[sorted_indices]\n",
    "# Reorganize the outputs based on labels\n",
    "outputs = outputs[sorted_indices]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "scatter = ax.scatter(outputs.numpy()[:, 0], outputs.numpy()[:, 2], c=labels.numpy(), cmap='tab10', alpha=0.8)\n",
    "fig.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "eaPznfesrd3j",
    "outputId": "4cf87a7b-1ea1-441e-e3bf-310b6801432f"
   },
   "outputs": [],
   "source": [
    "# Calculate the distance matrix\n",
    "distances = 1 - sim_matrix(outputs, outputs)\n",
    "\n",
    "# Plot the distance matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "threshold = 0.5  # Set the threshold for visualization\n",
    "binary_distances = 1*(distances > threshold)\n",
    "\n",
    "plt.imshow(distances, vmin=0., vmax=1.,cmap='hot', aspect='auto')  # 'aspect' ensures proper aspect ratio\n",
    "#plt.imshow(binary_distances, vmin=0., vmax=1.,cmap='hot', aspect='auto')  # 'aspect' ensures proper aspect ratio\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distance Matrix')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Sample Index')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0OXDqm-sy1u",
    "outputId": "dd2b0457-7ca2-43bd-b669-047d04c3e08e"
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.1,0.55,10)\n",
    "for threshold in thresholds:\n",
    "    binary_distances = distances < threshold\n",
    "    correct_predictions = 0\n",
    "    for label in range(10):\n",
    "        # submatrix indices\n",
    "        sub_ind = labels==label\n",
    "        correct_predictions += binary_distances[sub_ind,:][:,sub_ind].sum().item()**0.5\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    print('Threshold :  {:.4f}'.format(threshold))\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do0Uh8YYn2o4"
   },
   "source": [
    "Extensions:\n",
    "- Triplet mining\n",
    "- [Self-supervised approaches](https://arxiv.org/pdf/2002.05709.pdf)\n",
    "- [re-identification](https://arxiv.org/pdf/2001.04193.pdf)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
