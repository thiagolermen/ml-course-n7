{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgiKnAs1BbN"
      },
      "source": [
        "**Exercice : Un GAN conditionnel**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cet exercice, il s'agit d'implémenter un Wasserstein-GAN conditionnel. Les aspects théoriques sont laissés de côté: le but est seulement de construire la boucle d'apprentissage.\\\n",
        "Le contexte est le suivant: on se donne un jeu d'images représentatives d'un domaine $\\mathcal{D}$.\\\n",
        "Le GAN classique permet de générer de nouvelles images de $\\mathcal{D}$. Dans cet exercice, nous allons générer des images compatibles avec une liste de valeurs de pixels données a priori.\n",
        "\n",
        "Les cellules suivantes permettent de visualiser le jeu disponible."
      ],
      "metadata": {
        "id": "juWscSbuBqHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports nécessaires\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cLQjVEFlw4O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Liens valable jusqu'au 17/01/2024:\n",
        "# data à charger:\n",
        "! wget https://www.grosfichiers.com/L7R8MLxtfzG_NwC5CzNnTSt\n",
        "! tar xvf L7R8MLxtfzG_NwC5CzNnTSt\n",
        "! rm L7R8MLxtfzG_NwC5CzNnTSt\n",
        "# module à charger\n",
        "! wget https://www.grosfichiers.com/HAnmgiuVNGn_XtdcYCeMNnJ\n",
        "! mv HAnmgiuVNGn_XtdcYCeMNnJ utile_BE.py\n",
        "from utile_BE import *"
      ],
      "metadata": {
        "id": "kt6oFLXcwdQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# proportion de pixels conservés dans yi:\n",
        "dens_obs = 0.005\n",
        "\n",
        "x , y , z = gen_condDCGAN(6,dens_obs)\n",
        "\n",
        "# images complètes xi\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
        "\n",
        "# images fragmentaires yi: quelques pixels de xi prélevées au hasard\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(y, 6, fig2, k=0, min_scale=-0.2,max_scale=1)\n",
        "\n",
        "# zi : échantillon d'un vecteur gaussien centré réduit\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)\n"
      ],
      "metadata": {
        "id": "k0SJ7-1uxRDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La première ligne contient un échantillon d'images complètes $x^i$. Ces images représente un champ scalaire à valeurs positives ou nulles.\n",
        "\n",
        "Pour former les images framgmentaires $y^i$ (seconde ligne d'image), on a sélectionné au hasard 0.5% des pixels de chaque $x^i$, dont on a conservé les valeurs. Les valeurs de tous les autres pixels ont été fixées à -0.1.\\\n",
        "A considérer les $x^i$ (resp. $y^i$) comme l'échantillon d'une variable aléatoire $X$ (resp. $Y$), le but de l'exercice peut se reformuler ainsi: nous allons tenter d'échantilloner la loi $\\mathcal{L}_{X|Y}$."
      ],
      "metadata": {
        "id": "fq4Rs0u_JODF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Décrire brièvement le GAN classique. De combien de réseaux est-il constitué? Quels sont leur rôles respectifs ?"
      ],
      "metadata": {
        "id": "jrlcbIyjMD_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Ici, pour le générateur $G$, nous utilisons un FCN. Dans le GAN classique, les entrées sont des réalisations d'un vecteur gaussien centré réduit ($z_i$).\\\n",
        "Pour pouvoir prendre en compte le conditionnement par les $x_i$, $G$ doit prendre en entrée les $z_i$ et les $x_i$ (on les concaténera).\\\n",
        "Justifier que, de son côté, le discriminateur doit prendre en entrée les $G(x_i)$ et les $z_i$.\\\n",
        "Compléter la cellule suivante en conséquence."
      ],
      "metadata": {
        "id": "LnN0ReggUB_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndf = 32\n",
        "n_channels = ...\n",
        "n_classes = ...\n",
        "size = 16\n",
        "\n",
        "# les classes UNet et Discriminator sont codées dans utile_BE\n",
        "netG = UNet(n_channels, n_classes, size).cuda()\n",
        "netD = Discriminator(n_channels).cuda()"
      ],
      "metadata": {
        "id": "sR87TuzTxO-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** En vous inspirant de la correction du TP3, compléter la boucle d'apprentissage et la faire tourner sur dix époques:"
      ],
      "metadata": {
        "id": "5LmGDFi-N8eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramétrage de la SGD\n",
        "batch_size = 128\n",
        "num_batches_generator = 200\n",
        "num_epochs = 10\n",
        "\n",
        "# Paramètres de l'optimizer\n",
        "lr = 0.0005\n",
        "beta1 = 0. # inertie de la SGD\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
      ],
      "metadata": {
        "id": "UV4z0Ya4N2cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_label = 1.\n",
        "fake_label = 0."
      ],
      "metadata": {
        "id": "R06-r2swxdM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour garder les traces des images générées à partir d'un échantillon de $z_i$ fixé:\n",
        "fixed_x , fixed_y , fixed_z = gen_condDCGAN(8, p = dens_obs)\n",
        "\n",
        "# Entrée fixe du générateur:\n",
        "fixed_yz = torch.cat((fixed_y,fixed_z), dim=1).cuda()\n",
        "\n",
        "# Listes\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Autres hyper-paramètres\n",
        "n_critic = 5\n",
        "clip = 0.01"
      ],
      "metadata": {
        "id": "ALm9zO1Jxex0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i in range(num_batches_generator):\n",
        "\n",
        "        ############################\n",
        "        # (1) maximisation de log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        netG.train()\n",
        "        # Ici, on procède à plusieurs (n_critic) étapes d'optimisation\n",
        "        # du discriminateur.\n",
        "        for j in range(n_critic):\n",
        "\n",
        "            x , y , z = gen_condDCGAN(batch_size, p = dens_obs)\n",
        "\n",
        "            # mise sur carte GPU\n",
        "            ...\n",
        "\n",
        "            # concaténations :\n",
        "\n",
        "            xy = ...\n",
        "            yz = ...\n",
        "\n",
        "            output_xy = netD(xy)\n",
        "\n",
        "            fake = netG(yz)\n",
        "            fake = fake.detach()\n",
        "            fakey = torch.cat((fake,y),dim=1)\n",
        "            output_fakey = netD(fakey)\n",
        "\n",
        "            # régularisation par gradient penalty\n",
        "\n",
        "            gradient_penalty = calculate_gradient_penalty(netD,\n",
        "                                                              xy.data,\n",
        "                                                              fakey.data)\n",
        "            # calcul de l'erreur du discriminateur et mise à jour des gradients:\n",
        "            ....\n",
        "\n",
        "\n",
        "        ############################\n",
        "        # Maximisation de log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "\n",
        "        fake = ...\n",
        "        fakey = ...\n",
        "\n",
        "        output_fakey = ...\n",
        "\n",
        "        errG = - output_fakey.mean()\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
        "                  % (epoch+1, num_epochs, i, num_batches_generator,\n",
        "                     errD.item()))\n",
        "\n",
        "        # Enregistrement des losses\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(-errD.item())\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        netG.eval()\n",
        "        fake = netG(fixed_yz.cuda()).detach().cpu()\n",
        "\n",
        "    img_list.append(fake)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nHQRgCR0xiC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Visualiser quelques images et commentez."
      ],
      "metadata": {
        "id": "Zm052iJnVdiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img_list))\n",
        "voir_batch2D(img_list[-1], 8, fig1, k=0, min_scale=0,max_scale=1)\n"
      ],
      "metadata": {
        "id": "r5T6D9W7xq6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6** Pour obtenir un GAN qui tienne compte de la condition contenue dans les $y_i$, il est nécessaire de pousser l'apprentissage plus loin. Le fichier *data/netG_180ep_WGP_scheduler75_lr005.pt* contient les poids obtenus après apprentissage sur 300 époques.\n",
        "Charger ces poids et visualiser plusieurs images pour les mêmes entrée $x_i$ et $z_i$. Vérifier la cohérence et conclure."
      ],
      "metadata": {
        "id": "xlQOE8U7U6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.load('data/netG_180ep_WGP_scheduler75_lr005.pt')\n",
        "... = ... weights['model_state_dict'])"
      ],
      "metadata": {
        "id": "AfHi7rNIWrbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG.eval()\n",
        "\n",
        "x , y , z = gen_condDCGAN(6, p = dens_obs)\n",
        "\n",
        "...\n",
        "\n",
        "for i in range(n):\n",
        "    _ , _ , z = gen_condDCGAN(6, p = dens_obs)\n",
        "\n",
        "    ...\n",
        "\n",
        "fig1 = plt.figure(4, figsize=(36, 6))\n",
        "voir_batch2D(real_and_fakes, 6, fig1, k=0, min_scale=0, max_scale=1)\n"
      ],
      "metadata": {
        "id": "Kp4NHl_mxsgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}