{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSgiKnAs1BbN"
   },
   "source": [
    "# Practical session nÂ°5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvaKH1dZvg2B"
   },
   "source": [
    "## Part II: Sampling with GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--emH6d31Ahl"
   },
   "source": [
    "In this section, we aim to characterize a distribution in an image domain, rather than at the pixel level.\n",
    "\n",
    "In high dimensions, especially on real images, the joint distribution is not modelable. It is not feasible to seek its density. However, we can attempt to sample from this distribution by relying on an existing set of images.\n",
    "We will start by doing this without worrying about the conditional aspect:\n",
    "in **Exercise 1**, the goal is to build a **generative model** that samples a domain of synthetic images.\n",
    "\n",
    "Most recent generative models are primarily constructed from deep neural networks. In the field of image generation, one of the main approaches is based on **GANs** (Generative Adversarial Networks). **Exercise 1** illustrates this approach in its simplest version, while **Exercise 2** presents some variations.\n",
    "Finally, **Exercise 3** gives us the opportunity to revisit the conditional aspect. The GAN approach is modified to sample from an implicit conditional distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qndq7kQQISSb"
   },
   "source": [
    "**Exercise 1** A first GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmFMn35Djs05"
   },
   "source": [
    "The principle of GAN is simple. We have:\n",
    "- A random vector $Z$, sampled from a simple distribution, for example, a centered reduced Gaussian vector.\n",
    "- A generative network $G_\\theta$ ($\\theta$ represents the network's weights) that generates an image $G_\\theta(Z)$.\n",
    "- A discriminator network $D_\\rho$ (similar notation as before), ending with a sigmoid function that classifies an image $x$ as \"real\" ($D_\\rho(x) > 0.5$) or \"fake\" ($D_\\rho(x) < 0.5$).\n",
    "\n",
    "In the following, we omit the notations $\\rho$ and $\\theta$.\n",
    "\n",
    "The algorithm consists of training $G$ and $D$ on adversarial tasks:\n",
    "- $D_\\rho$ is trained to distinguish images from the dataset ($x^{(i)}$) from images generated by $G_\\theta$ (denoted as $G(z^{(i)})$). In the [original GAN paper](https://arxiv.org/abs/1406.2661), the authors use cross-entropy as the cost function. For a pair of two images, one fake and the other real, the cost is written as:\n",
    "  $$  - {\\bigg [} \\ln(D(x^{(i)})) + \\ln(1 - D(G(z^{(i)})) {\\bigg ]}$$\n",
    "\n",
    "- $G_\\theta$ is trained to \"fool\" the discriminator with the adversarial cost function:\n",
    "  $$  \\ln(1 - D(G(z^{(i)}))) $$\n",
    "\n",
    "A theoretical analysis of the problem is covered in the supplementary exercise sheet. Here, we implement the algorithm on synthetic images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IQ1Flnxj_Js",
    "outputId": "7cd47e87-20ed-44ae-929f-fc19c59b5245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "# import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBewKJe7i4oa"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/relmonta/ml-student.git\n",
    "! cp ml-student/TP5/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFNkLntQujEZ"
   },
   "source": [
    "Let's first define an image generation problem. The following function samples the random image $X$ and the random vector $Z$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_TP5 import *\n",
    "from utils_TP5_exo3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvM6l5tfG4cO"
   },
   "outputs": [],
   "source": [
    "# Rectangle proportion in the image:\n",
    "lambda_rec = 0.0\n",
    "\n",
    "x, z = gen_DCGAN(6, lambda_rec=lambda_rec)\n",
    "\n",
    "# Clean versions (individual cells)\n",
    "fig1 = plt.figure(1, figsize=(36, 6))\n",
    "voir_batch2D(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
    "\n",
    "fig3 = plt.figure(3, figsize=(36, 6))\n",
    "voir_batch2D(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKi_mw5LueFp"
   },
   "source": [
    "**Q1** The vector $Z$ is an image. What type of network is suitable for $G$? Instantiate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MlYsVAtFDXi"
   },
   "source": [
    "**Q2** The Discriminator class is used to encode the discriminator. Instantiate it and use the *weight_init* function to initialize the network's weights. What type of network do you obtain in this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0wU8ftRHUSr"
   },
   "outputs": [],
   "source": [
    "ndf = 32\n",
    "nc = 1\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netD = Discriminator().cuda()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mSpp0qRw-TC"
   },
   "source": [
    "Let's now specify some training parameters (most of them are standard for GANs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSzW08JSGbKU"
   },
   "outputs": [],
   "source": [
    "# Fixing the seed (to reproduce results)\n",
    "manualSeed = 1\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Number of parallel processes:\n",
    "workers = 2\n",
    "\n",
    "# Image size\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels\n",
    "nc = 1\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of batches per epoch\n",
    "num_batches = 200\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam\n",
    "beta1 = 0.5  # Sometimes simply 0.\n",
    "\n",
    "# Number of GPUs\n",
    "ngpu = 1\n",
    "\n",
    "# Cross-entropy\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Labels for real and fake images\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKjdWbBBxedy"
   },
   "outputs": [],
   "source": [
    "# To observe how G(z) evolves with z fixed along the training:\n",
    "_ , fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
    "fixed_z = fixed_z.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gSP_UYGxokD"
   },
   "source": [
    "**Q3** Launch the following code and add comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxWy6OkTzI5A"
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        # ...\n",
    "        x, z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
    "\n",
    "        # ...\n",
    "        x = x.cuda()\n",
    "\n",
    "        # ...\n",
    "        z = z.cuda()\n",
    "\n",
    "        # STEP 1: discriminator optimization\n",
    "\n",
    "        # ...\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # ...\n",
    "        D_real = netD(x).view(-1)\n",
    "\n",
    "        # ...\n",
    "        b_size = x.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float).cuda()\n",
    "        errD_real = criterion(D_real, label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # ...\n",
    "        D_real = D_real.mean().item()\n",
    "\n",
    "        # ...\n",
    "        fake = netG(z.cuda())\n",
    "\n",
    "        # ...\n",
    "        D_fake = netD(fake.detach()).view(-1)\n",
    "\n",
    "        # ...\n",
    "        label.fill_(fake_label)\n",
    "        errD_fake = criterion(D_fake, label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        # ...\n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        # ...\n",
    "        optimizerD.step()\n",
    "\n",
    "        # ...\n",
    "        D_fake = D_fake.mean().item()\n",
    "\n",
    "        # STEP 2: ...\n",
    "        netG.zero_grad()\n",
    "\n",
    "        # ...\n",
    "        D_fake2 = netD(fake).view(-1)\n",
    "\n",
    "        # ...\n",
    "        label.fill_(real_label)\n",
    "        errG = criterion(D_fake2, label)\n",
    "        errG.backward()\n",
    "\n",
    "        # ...\n",
    "        D_fake2 = D_fake2.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, num_batches,\n",
    "                     errD.item(), errG.item(), D_real, D_fake, D_fake2))\n",
    "\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # ...\n",
    "        if (iters % 100 == 0) or ((epoch == num_epochs - 1) and (i == num_batches - 1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_z).detach().cpu()\n",
    "            img_list.append(fake)\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBCnpIJFyIpz"
   },
   "source": [
    "**Q4** Plot the evolution of the cost functions for the generator and discriminator. Observe the generated images and comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsozbuqsyhnr"
   },
   "source": [
    "**Q5** Restart training with additional rectangles on the image. Visualize and comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDrBZW-wME-x"
   },
   "outputs": [],
   "source": [
    "# Rectangle proportion in the image :\n",
    "lambda_rec = 0.00025\n",
    "\n",
    "x , z = gen_DCGAN(6,lambda_rec = lambda_rec)\n",
    "\n",
    "# Propre versions (only cells)\n",
    "fig1 = plt.figure(1, figsize=(36, 6))\n",
    "voir_batch2D(x, 6, fig1, k=0, min_scale=0,max_scale=1)\n",
    "\n",
    "\n",
    "fig3 = plt.figure(3, figsize=(36, 6))\n",
    "voir_batch2D(z, 6, fig3, k=0, min_scale=0,max_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7pVjRQIUCJY"
   },
   "source": [
    "**Exercise nÂ°2** Wasserstein-GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIIq4Ypsyf2B"
   },
   "source": [
    "To facilitate the convergence of GANs, several approaches have been explored. In particular:\n",
    "- Giving the discriminator more time to converge at each step.\n",
    "- Keep the Lipschitzianity of the discriminator. This option takes its root in an interesting theoretical approach (see the supplementary exercise sheet). It can be done:\n",
    "\n",
    "  * by constraining the weights of the discriminator to remain within a given interval (see the paper introducing WGANs [(Wasserstein-GANs)](https://arxiv.org/abs/1701.07875).\n",
    "\n",
    "  * by [gradient penalization](https://arxiv.org/pdf/1704.00028.pdf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUnziPsr3zO_"
   },
   "source": [
    "**Q2** In the following cells, these three approaches are coded. Say where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcadfcHAWo_U"
   },
   "outputs": [],
   "source": [
    "nc = 1\n",
    "ndf = 32\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJIShnggoy6y"
   },
   "outputs": [],
   "source": [
    "def calculate_gradient_penalty(model, real_images, fake_images):\n",
    "    alpha = torch.randn((real_images.size(0), 1, 1, 1)).cuda()\n",
    "    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n",
    "\n",
    "    model_interpolates = model(interpolates)\n",
    "    grad_outputs = torch.ones(model_interpolates.size(), requires_grad=False).cuda()\n",
    "\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=model_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_VnWS14zIIZ"
   },
   "outputs": [],
   "source": [
    "n_channels, n_classes,size = 1, 1, 16\n",
    "netG = UNet(n_channels, n_classes, size).cuda()\n",
    "\n",
    "netD = Discriminator()\n",
    "netD.apply(weights_init)\n",
    "netD = netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ml1gikCmxLNo"
   },
   "outputs": [],
   "source": [
    "# Proportion of rectangle in the image:\n",
    "lambda_rec = 0.00025\n",
    "\n",
    "# Fixing the seed for reproducibility:\n",
    "manualSeed = 1\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Number of parallel processes:\n",
    "workers = 2\n",
    "\n",
    "# Image size:\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels:\n",
    "nc = 1\n",
    "\n",
    "# Batch size:\n",
    "batch_size = 64\n",
    "\n",
    "# Number of batches per epoch (for the generator):\n",
    "num_batches_generator = 200\n",
    "num_epochs = 30\n",
    "\n",
    "# Learning rate:\n",
    "lr = 0.0001\n",
    "\n",
    "# Beta1 hyperparameter for Adam:\n",
    "beta1 = 0.  # In the paper introducing gradient penalty\n",
    "\n",
    "# Number of GPUs:\n",
    "ngpu = 1\n",
    "\n",
    "# Cross-entropy & label conventions:\n",
    "criterion = nn.BCELoss()\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Gradient penalty (gp) or classic WGAN:\n",
    "add_gp = True\n",
    "\n",
    "# Setup Adam optimizers for both G and D:\n",
    "# If gradient penalty:\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# If not:\n",
    "# optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
    "# optimizerG = optim.RMSprop(netG.parameters(), lr=lr)\n",
    "\n",
    "# Schedulers:\n",
    "step_size = 31\n",
    "gamma = 0.2\n",
    "schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=step_size, gamma=gamma)\n",
    "schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HOcNJdaV51G"
   },
   "outputs": [],
   "source": [
    "# To observe how G(z) evolves with fixed z during training:\n",
    "_ ,  fixed_z = gen_DCGAN(batch_size, lambda_rec=lambda_rec)\n",
    "fixed_z = fixed_z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AUXImtWV1PN"
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "n_critic = 5\n",
    "clip = 0.01\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches_generator):\n",
    "        netG.train()\n",
    "        for j in range(n_critic):\n",
    "            x , z = gen_DCGAN(batch_size, lambda_rec = lambda_rec)\n",
    "\n",
    "\n",
    "            netD.zero_grad()\n",
    "            real = x.cuda()\n",
    "            output_real = netD(real)\n",
    "            fake = netG(z.cuda())\n",
    "            output_fake = netD(fake.detach())\n",
    "\n",
    "            # Ici, on limite les gradients du discriminateur:\n",
    "            if add_gp:\n",
    "                gradient_penalty = calculate_gradient_penalty(netD,\n",
    "                                                   real.data, fake.data)\n",
    "                errD = output_fake.mean() - output_real.mean() + 10 * gradient_penalty\n",
    "\n",
    "            else :\n",
    "                errD = output_fake.mean() - output_real.mean()\n",
    "\n",
    "            errD.backward()\n",
    "\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            if not add_gp:\n",
    "                for p in netD.parameters():\n",
    "                    p.data.clamp_(-clip, clip)\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "#        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        fake = netG(z.cuda())\n",
    "        output_fake = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = - output_fake.mean()\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "#        D_G_z2 =  - output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
    "                  % (epoch+1, num_epochs, i, num_batches_generator,\n",
    "                     errD.item()))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "\n",
    "    with torch.no_grad():\n",
    "        netG.eval()\n",
    "        fake = netG(fixed_z.cuda()).detach().cpu()\n",
    "#            img_list.append(vutils.make_grid(fake, padding=2, normalize=False))\n",
    "    img_list.append(fake)\n",
    "\n",
    "\n",
    "    schedulerD.step()\n",
    "    schedulerG.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFQetJ8E21xW"
   },
   "source": [
    "**Q3** Plot the learning curves and some gerated outputs. Can we still observe mode collapse in these images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_8twouW-Yz_"
   },
   "source": [
    "**Q4** Let's finally see the results of training over several hours. Load the UNet trained for 600 epochs (*netG_600.pt*) and visualize the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QR9sW73QDkv"
   },
   "outputs": [],
   "source": [
    "n_channels, n_classes,size = 1, 1, 16\n",
    "netG_600ep = UNet(n_channels, n_classes, size).cuda()\n",
    "path_netG = \"Ex2_netG_600ep_WGP_lr0001.pt\"\n",
    "\n",
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxKXpYFWqML3"
   },
   "source": [
    "**Exercice nÂ°3** A conditional GAN.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn-dvMLA_x3V"
   },
   "source": [
    "In this exercise, the goal is to implement a conditional Wasserstein-GAN. Once again, theoretical aspects are set aside; the objective is solely to construct the training loop.\n",
    "The context is as follows: we have a set of images representing a domain ð.\n",
    "The traditional GAN generates new images from ð. In this exercise, we will generate images compatible with a given list of pixel values a priori.\n",
    "\n",
    "The following cells allow visualization of the available dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQEBbOQq_xCz"
   },
   "outputs": [],
   "source": [
    "# Proportion of pixels preserved in yi:\n",
    "obs_density = 0.005\n",
    "\n",
    "x, y, z = gen_condDCGAN(6, obs_density)\n",
    "\n",
    "# Full images xi\n",
    "fig1 = plt.figure(1, figsize=(36, 6))\n",
    "visualize_2D_batch(x, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
    "\n",
    "# Fragmentary images yi: a few pixels randomly sampled from xi\n",
    "fig2 = plt.figure(2, figsize=(36, 6))\n",
    "visualize_2D_batch(y, 6, fig2, k=0, min_scale=-0.2, max_scale=1)\n",
    "\n",
    "# zi: sample from a centered reduced Gaussian vector\n",
    "fig3 = plt.figure(3, figsize=(36, 6))\n",
    "visualize_2D_batch(z, 6, fig3, k=0, min_scale=0, max_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bOzh1IW_-ud"
   },
   "source": [
    "**Q1** Drawing inspiration from the previous exercise, complete the training loop and run it for ten epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtK8wz6iARji"
   },
   "outputs": [],
   "source": [
    "# SGD Setup\n",
    "batch_size = 128\n",
    "num_batches_generator = 200\n",
    "num_epochs = ...\n",
    "\n",
    "\n",
    "# Optimizer Parameters\n",
    "lr = 0.0005\n",
    "beta1 = 0.  # SGD momentum\n",
    "\n",
    "# nn setup\n",
    "ndf = 32\n",
    "n_channels = ...\n",
    "n_classes = ...\n",
    "size = 16\n",
    "\n",
    "netG = UNet(n_channels, n_classes, size).cuda()\n",
    "netD = Discriminator(n_channels).cuda()\n",
    "\n",
    "# optimizers\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQX7RyRrAWPj"
   },
   "outputs": [],
   "source": [
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klbcqnE8AYm7"
   },
   "outputs": [],
   "source": [
    "# To keep track of generated images from a fixed sample of $z_i$:\n",
    "fixed_x, fixed_y, fixed_z = gen_condDCGAN(8, p=dens_obs)\n",
    "\n",
    "# Fixed input for the generator:\n",
    "fixed_yz = torch.cat((fixed_y, fixed_z), dim=1).cuda()\n",
    "\n",
    "# Lists\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "# Other hyperparameters\n",
    "n_critic = 5\n",
    "clip = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1-D_aF-AcCj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i in range(num_batches_generator):\n",
    "\n",
    "        ############################\n",
    "        # (1) Maximization of log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        netG.train()\n",
    "        # Here, we perform multiple (n_critic) optimization steps for the discriminator.\n",
    "        for j in range(n_critic):\n",
    "\n",
    "            x, y, z = gen_condDCGAN(batch_size, p=dens_obs)\n",
    "\n",
    "            # Move to GPU\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            z = z.cuda()\n",
    "\n",
    "            # Concatenations:\n",
    "            xy = torch.cat((x, y))\n",
    "            yz = torch.cat((y, z))\n",
    "\n",
    "            output_xy = netD(xy)\n",
    "\n",
    "            fake = netG(yz)\n",
    "            fake = fake.detach()\n",
    "\n",
    "            fakey = torch.cat((fake, y), dim=1)\n",
    "            output_fakey = netD(fakey)\n",
    "\n",
    "            # Regularization by gradient penalty\n",
    "            gradient_penalty = calculate_gradient_penalty(netD, xy.data, fakey.data)\n",
    "\n",
    "            # Calculate discriminator error and update gradients:\n",
    "            label = torch.full((xy.size(0),), real_label, dtype=torch.float).cuda()\n",
    "            err_D_real = criterion(output_xy.view(-1), label)\n",
    "            errD_real.backward()\n",
    "            label.fill_(fake_label)\n",
    "            errD_fake = criterion(output_fakey, label)\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = err_D_real + errD_fake  # In case we want to store it later\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # Maximization of log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "\n",
    "        fake = netD(fake).view(-1)\n",
    "        fakey = torch.cat((fake, y), dim=1)\n",
    "\n",
    "        output_fakey = netD(fakey)\n",
    "\n",
    "        errG = -output_fakey.mean()\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i, num_batches_generator,\n",
    "                     errD.item()))\n",
    "\n",
    "        # Record losses\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(-errD.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        netG.eval()\n",
    "        fake = netG(fixed_yz.cuda()).detach().cpu()\n",
    "\n",
    "    img_list.append(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq7jeF2FAjDC"
   },
   "source": [
    "**Q2** Visualize some images and comment on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1QHK-AGApMr"
   },
   "source": [
    "**Q3** To obtain a GAN that takes into account the condition contained in $y_i$, it is necessary to push the training further. The file *netG_180ep_WGP_scheduler75_lr005.pt* contains the weights obtained after training for 300 epochs. Load these weights and visualize several images for the same inputs $x_i$ and $z_i$. Check the coherence and draw conclusions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
